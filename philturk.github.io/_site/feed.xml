<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-02-20T16:06:51-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Tips, Tricks, and Tidbits in Data Science</title><subtitle>The Center for Outcomes Research and Evaluation (CORE) partners with investigators  across Atrium Health to generate real-world evidence that advances the delivery of  high-quality, patient-centered care.</subtitle><author><name>Philip Turk, MS, PhD</name></author><entry><title type="html">When Your Distribution Looks All Skewed Up</title><link href="http://localhost:4000/core/post/2021/02/20/post02.html" rel="alternate" type="text/html" title="When Your Distribution Looks All Skewed Up" /><published>2021-02-20T11:00:00-05:00</published><updated>2021-02-20T11:00:00-05:00</updated><id>http://localhost:4000/core/post/2021/02/20/post02</id><content type="html" xml:base="http://localhost:4000/core/post/2021/02/20/post02.html">&lt;p&gt;&lt;strong&gt;Skewness&lt;/strong&gt; is a measure of the degree of asymmetry of a distribution of numbers.  Let’s take a look at an approach to quantify it.&lt;/p&gt;

&lt;p&gt;Consider a population of size \(N\) in which the values of the random variable $Y$ are $y_1, y_2, \ldots, y_N$. The “centered population moment of order 3” is defined as:&lt;/p&gt;

\[\nonumber M_3 = \frac{1}{N}\sum_{i = 1}^{N}(y_i - \mu)^3\]

&lt;p&gt;where $\mu$ is the population mean.  $M_3$ reflects the skewness of the population distribution.&lt;/p&gt;

&lt;p&gt;The (standardized) population coefficient of skewness is denoted by $\kappa_3$ (“kappa sub 3”) and defined by:&lt;/p&gt;

\[\nonumber \kappa_3 = \frac{M_3}{\sigma^3}\]

&lt;p&gt;where $\sigma$ is the population standard deviation.  By construction, this measure is not affected either by the mean of the population or by the standard deviation of the population. In symmetric distributions, $\kappa_3 = 0$. In right-skewed distributions, $\kappa_3 &amp;gt; 0$ and in left-skewed distributions, $\kappa_3 &amp;lt; 0$.   As a rule of thumb, we have:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If $\kappa_3$ is less than -1 or greater than 1, then the distribution is highly skewed;&lt;/li&gt;
  &lt;li&gt;If $\kappa_3$ is between -1 and -0.5 or between 0.5 and 1, then the distribution is moderately skewed;&lt;/li&gt;
  &lt;li&gt;If $\kappa_3$ is between -0.5 and 0.5, then the distribution is approximately symmetric.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\kappa_3$ can be estimated using sample data. Simply replace the population mean $\mu$ with the sample mean $\bar{Y}$, and the population standard deviation $\sigma$ with the sample standard deviation $S$ (using the sample size $n$, not $n - 1$, in the denominator).  The estimate is denoted as $\widehat{\kappa}_3$, the sample coefficient of skewness.  Please note that a more formal procedure can be developed to test whether $\widehat{\kappa}_3$ is significantly different from 0.&lt;/p&gt;

&lt;p&gt;To compute $\widehat{\kappa}_3$ is easy to do in R.  One can code their own function or use a package.  The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;skewness()&lt;/code&gt; function in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;EnvStats&lt;/code&gt; package computes the sample coefficient of skewness as described above by invoking the so-called “moment” option.  For example, consider the following toy data set:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; library(EnvStats)
&amp;gt; my_data &amp;lt;- c(1,1,1,1,1,2,2,2,2,3,3,3,4,4,5)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To compute $\widehat{\kappa}_3$, we do:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; skewness(my_data, method = &quot;moment&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Following is a histogram displaying the data:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/plots/bpost02-plot-1.png&quot; alt=&quot;My helpful screenshot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We obtain $\widehat{\kappa}_3 = 0.59$.  By the rules of thumb, we have moderate right-skew.&lt;/p&gt;

&lt;p&gt;By using the statistic $\widehat{\kappa}_3$, we can look for a departure from symmetry, how the departure manifests itself, and the strength of the departure.  It provides some quantitative rigor as a companion to a histogram and therefore can be a useful tool in practice. For example, I have used this in a marketing setting where there was interest to see how sales managers differed with respect to rating assessments of their teams. Perhaps you will find an application in your future, too.&lt;/p&gt;</content><author><name>Philip Turk, MS, PhD</name></author><category term="CORE" /><category term="post" /><summary type="html">Skewness is a measure of the degree of asymmetry of a distribution of numbers. Let’s take a look at an approach to quantify it.</summary></entry><entry><title type="html">The Complete Data Scientist</title><link href="http://localhost:4000/core/post/2020/10/31/post01.html" rel="alternate" type="text/html" title="The Complete Data Scientist" /><published>2020-10-31T16:00:00-04:00</published><updated>2020-10-31T16:00:00-04:00</updated><id>http://localhost:4000/core/post/2020/10/31/post01</id><content type="html" xml:base="http://localhost:4000/core/post/2020/10/31/post01.html">&lt;p&gt;Nowadays, because of high market demand and because of the rise of artificial intelligence (AI), many people are calling themselves a “data scientist”. But what does this job title actually mean? Many articles on the internet do a great job giving a comprehensive checklist of computational skills necessary to be a data scientist, but to me this view is too narrow. My approach in this short article is to give a brief overview of three general areas that I feel constitute a complete data scientist. They are not listed in any preferential order.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Computer skills&lt;/p&gt;

    &lt;p&gt;I list below a basic core set of tools that allow a data scientist to do his or her work and to stay current:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;R, especially the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tidyverse&lt;/code&gt; packages, and the ability to use R Markdown.&lt;/li&gt;
      &lt;li&gt;Python, and the ability to use JupyterLab.  There are many popular libraries you can learn as you go (e.g., NumPy, Pandas, Matplotlib, etc.).&lt;/li&gt;
      &lt;li&gt;The ability to use a Git + GitHub workflow.&lt;/li&gt;
      &lt;li&gt;The ability to be able to move around one of The Big Three big cloud computing platforms (e.g., AWS).  This also includes a basic familiarity with Spark (Databricks is a nice  platform).&lt;/li&gt;
      &lt;li&gt;If you are going to do a lot of data engineering, then knowing how to use SQL is important.  &lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;This list will undoubtedly not satisfy everyone, but it is not meant to be exhaustive. Because of my earlier training, there are still times when I find myself reaching for SAS for various reasons.  You might also find yourself having to pick up a skill depending on where you work. For example, you might find yourself working for a company that will insist you produce graphics with Tableau or program in Ruby.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The ability to apply statistics and solve problems.&lt;/p&gt;

    &lt;p&gt;It will be important that you have the ability to apply a broad set of statistical skills.  You will use basic inferential statistics (e.g., &lt;em&gt;t&lt;/em&gt;-tests, simple linear regression, etc.) more than you think and deep learning less than you think.&lt;/p&gt;

    &lt;p&gt;Having a basic understanding of some or all of the classic fields of statistics, like sampling, experimental design, time series, survival analysis, spatial statistics, Bayesian statistics, categorical data analysis, nonparametrics, and multivariate statistics is important. Why?  Because these fields can be used for many problems and you never know what sort of problem you will be tasked to work on.&lt;/p&gt;

    &lt;p&gt;Consulting practice and experience analyzing actual data are like gold, and the more practice and experience you get, the stronger a data scientist you will become. It teaches you key concepts of staying curious, critical thinking, solving difficult problems, and the art of being able to communicate results to people that oftentimes know very little about statistics. Keep studying and evolving in your ability to apply statistics to solve problems. There are some good online courses hosted on Udemy and DataCamp, for example. Just take care to make sure that the course is taught by someone who is reasonably credentialed. As well, there are some great books out there that you can read and teach yourself that cool machine learning skill you’ve been hearing about :)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Having a background in statistical theory and math.&lt;/p&gt;

    &lt;p&gt;It has been my experience that many people who call themselves data scientists are strong with computers, but when it comes to statistics, they have a limited understanding of what it is they are doing and why they are doing it. This is unfortunate because what happens when you face a tough problem that has no solution worked out on the internet or you have to derive a tricky result on your own? Or perhaps you encounter an answer that doesn’t make sense or should be challenged.&lt;/p&gt;

    &lt;p&gt;Because of this, I think having an MS or PhD in Statistics or Data Science is crucial, and it should be a graduate program nicely stocked with some basic math courses (e.g., calculus, linear algebra, etc.).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Ok, let’s suppose you’ve worked hard and now check the box in all three areas. What about once we are in the workforce? There are some great annual conferences that allow you to stay current and attend technical workshops as part of your continued professional development.  For example, The Symposium on Data Science and Statistics comes to mind. The American Statistician comes out four times a year and gives about as nice and comprehensive an overview of what is current in statistics and data science as you will find. I much recommend reading this journal. If it is possible, it is worth the time to continue to publish peer-reviewed papers. These do not have to be only in high-impact theoretical journals within the statistics and data science realm. A solid paper evidencing an interdisciplinary collaboration can only help your professional credibility.&lt;/p&gt;

&lt;p&gt;In closing, I think it is important to have a blended balance of all three of these areas.  To be a complete data scientist, you cannot be strong only in computer skills (area 1), and ignore knowing how to apply statistics to solve problems (area 2), and ignore having a basic understanding of statistical and mathematical theory (area 3). Some people do not like to hear this because it is frankly harder to transition from application to theory than it is to transition from theory to application. However, to illuminate this point, I was informed the other day that a very large company I have worked for in the past currently has on staff several mid- and senior-level statisticians and data scientists to focus on areas 2 and 3 only. As for the actual turning the crank on the data analysis (area 1), all that is now shipped overseas for greatly reduced costs. Think about it.&lt;/p&gt;

&lt;p&gt;So that is the short definition of a complete data scientist I use in my own professional career and it has served me well so far. These are the skills I’ll be looking for when it comes to potential new data scientist hires for my team in &lt;a href=&quot;https://atriumhealth.org/research/multi-disciplinary-centers-and-cores/core&quot;&gt;CORE at Atrium Health&lt;/a&gt;.&lt;/p&gt;</content><author><name>Philip Turk, MS, PhD</name></author><category term="CORE" /><category term="post" /><summary type="html">Nowadays, because of high market demand and because of the rise of artificial intelligence (AI), many people are calling themselves a “data scientist”. But what does this job title actually mean? Many articles on the internet do a great job giving a comprehensive checklist of computational skills necessary to be a data scientist, but to me this view is too narrow. My approach in this short article is to give a brief overview of three general areas that I feel constitute a complete data scientist. They are not listed in any preferential order.</summary></entry></feed>